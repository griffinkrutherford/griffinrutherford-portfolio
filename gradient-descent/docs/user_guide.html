<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Gradient Descent Visualizer - User Guide</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            color: #333;
        }
        h1, h2, h3 {
            color: #6C1AFF;
        }
        .section {
            margin-bottom: 30px;
        }
        .screenshot {
            max-width: 100%;
            border: 1px solid #ddd;
            border-radius: 4px;
            margin: 20px 0;
        }
        code {
            background-color: #f5f5f5;
            padding: 2px 4px;
            border-radius: 4px;
            font-family: monospace;
        }
        .math {
            font-style: italic;
            margin: 20px 0;
            padding: 10px;
            background-color: #f9f9f9;
            border-left: 4px solid #6C1AFF;
        }
        .note {
            background-color: #fffde7;
            padding: 10px;
            border-left: 4px solid #ffd600;
            margin: 20px 0;
        }
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
        }
        th, td {
            border: 1px solid #ddd;
            padding: 8px;
            text-align: left;
        }
        th {
            background-color: #f2f2f2;
        }
    </style>
</head>
<body>
    <h1>Gradient Descent Visualizer - User Guide</h1>
    
    <div class="section">
        <h2>Introduction</h2>
        <p>
            The Gradient Descent Visualizer is an interactive educational tool designed to help you understand 
            how the gradient descent algorithm works across different types of functions. This guide will walk 
            you through the features and usage of the visualizer.
        </p>
    </div>
    
    <div class="section">
        <h2>Getting Started</h2>
        <p>
            When you first open the visualizer, you'll see three tabs at the top:
        </p>
        <ul>
            <li><strong>Single Variable</strong>: Visualize gradient descent on functions of one variable (1D → 1D)</li>
            <li><strong>Multivariate</strong>: Visualize gradient descent on functions of two variables (2D → 1D)</li>
            <li><strong>Complex</strong>: Visualize gradient descent on complex functions (ℂ → ℂ)</li>
        </ul>
        <p>
            Click on any tab to switch between these different visualization modes.
        </p>
    </div>
    
    <div class="section">
        <h2>Single Variable Mode</h2>
        <p>
            In this mode, you can visualize how gradient descent finds the minimum of a function of one variable.
        </p>
        
        <h3>Controls</h3>
        <ul>
            <li><strong>Function</strong>: Select a predefined function from the dropdown menu</li>
            <li><strong>Starting Point</strong>: Set the x-coordinate where the algorithm will start</li>
            <li><strong>Learning Rate (α)</strong>: Adjust how large each step will be</li>
            <li><strong>Reset</strong>: Reset the algorithm to the starting point</li>
            <li><strong>Step</strong>: Perform a single iteration of gradient descent</li>
            <li><strong>Run/Stop</strong>: Continuously run the algorithm or stop the animation</li>
        </ul>
        
        <h3>Visualization</h3>
        <p>
            The canvas shows:
        </p>
        <ul>
            <li>The function curve (blue line)</li>
            <li>The current position (red dot)</li>
            <li>The gradient at the current position (green arrow)</li>
            <li>The path taken by the algorithm (red line)</li>
        </ul>
        
        <h3>Status Display</h3>
        <p>
            Below the controls, you'll see the current status of the algorithm:
        </p>
        <ul>
            <li><strong>Iteration</strong>: The current iteration number</li>
            <li><strong>Position</strong>: The current x-coordinate</li>
            <li><strong>Value</strong>: The function value at the current position</li>
            <li><strong>Gradient</strong>: The slope of the function at the current position</li>
        </ul>
    </div>
    
    <div class="section">
        <h2>Multivariate Mode</h2>
        <p>
            In this mode, you can visualize how gradient descent finds the minimum of a function of two variables.
        </p>
        
        <h3>Controls</h3>
        <ul>
            <li><strong>Function</strong>: Select a predefined multivariate function</li>
            <li><strong>Starting Point</strong>: Set the (x,y) coordinates where the algorithm will start</li>
            <li><strong>Learning Rate (α)</strong>: Adjust how large each step will be</li>
            <li><strong>Reset</strong>: Reset the algorithm to the starting point</li>
            <li><strong>Step</strong>: Perform a single iteration of gradient descent</li>
            <li><strong>Run/Stop</strong>: Continuously run the algorithm or stop the animation</li>
        </ul>
        
        <h3>Visualization</h3>
        <p>
            The canvas shows:
        </p>
        <ul>
            <li>A contour plot of the function (colored regions)</li>
            <li>The current position (red dot)</li>
            <li>The gradient vector at the current position (green arrow)</li>
            <li>The path taken by the algorithm (red line with dots)</li>
        </ul>
        
        <h3>Status Display</h3>
        <p>
            Below the controls, you'll see the current status of the algorithm:
        </p>
        <ul>
            <li><strong>Iteration</strong>: The current iteration number</li>
            <li><strong>Position</strong>: The current (x,y) coordinates</li>
            <li><strong>Value</strong>: The function value at the current position</li>
            <li><strong>Gradient</strong>: The gradient vector at the current position</li>
        </ul>
    </div>
    
    <div class="section">
        <h2>Complex Mode</h2>
        <p>
            In this mode, you can visualize how gradient descent works on complex functions.
        </p>
        
        <h3>Controls</h3>
        <ul>
            <li><strong>Complex Function</strong>: Select a predefined complex function</li>
            <li><strong>Starting Point</strong>: Set the complex number (Re + Im*i) where the algorithm will start</li>
            <li><strong>Coloring Method</strong>: Choose how the complex function is visualized</li>
            <li><strong>Learning Rate (α)</strong>: Adjust how large each step will be</li>
            <li><strong>Reset</strong>: Reset the algorithm to the starting point</li>
            <li><strong>Step</strong>: Perform a single iteration of gradient descent</li>
            <li><strong>Run/Stop</strong>: Continuously run the algorithm or stop the animation</li>
        </ul>
        
        <h3>Visualization</h3>
        <p>
            The canvas shows:
        </p>
        <ul>
            <li>A domain coloring visualization of the complex function</li>
            <li>The current position in the complex plane (red dot)</li>
            <li>The gradient at the current position (green arrow)</li>
            <li>The path taken by the algorithm (red line with dots)</li>
        </ul>
        
        <h3>Coloring Methods</h3>
        <ul>
            <li><strong>Phase (Argument)</strong>: Colors based on the angle of the complex number</li>
            <li><strong>Modulus (Magnitude)</strong>: Colors based on the magnitude of the complex number</li>
            <li><strong>Combined</strong>: Uses both phase for hue and modulus for brightness</li>
        </ul>
        
        <h3>Status Display</h3>
        <p>
            Below the controls, you'll see the current status of the algorithm:
        </p>
        <ul>
            <li><strong>Iteration</strong>: The current iteration number</li>
            <li><strong>Position</strong>: The current complex number</li>
            <li><strong>Value</strong>: The magnitude of the function value</li>
            <li><strong>Gradient</strong>: The gradient at the current position</li>
        </ul>
    </div>
    
    <div class="section">
        <h2>Mathematical Background</h2>
        
        <h3>Gradient Descent Algorithm</h3>
        <p>
            Gradient descent is an optimization algorithm that finds the minimum of a function by iteratively 
            moving in the direction of steepest descent, as defined by the negative of the gradient.
        </p>
        
        <div class="math">
            x<sub>i+1</sub> = x<sub>i</sub> - α∇f(x<sub>i</sub>)
        </div>
        
        <p>Where:</p>
        <ul>
            <li>x<sub>i</sub> is the current position</li>
            <li>α is the learning rate</li>
            <li>∇f(x<sub>i</sub>) is the gradient at the current position</li>
            <li>x<sub>i+1</sub> is the next position</li>
        </ul>
        
        <h3>Complex Gradient Descent</h3>
        <p>
            For complex functions, the gradient descent algorithm minimizes |f(z)| by moving in the direction 
            of steepest descent, which is given by 2 * conjugate(f'(z)).
        </p>
        
        <div class="math">
            z<sub>i+1</sub> = z<sub>i</sub> - α * 2 * conjugate(f'(z<sub>i</sub>))
        </div>
    </div>
    
    <div class="section">
        <h2>Tips for Effective Use</h2>
        <ul>
            <li>Start with a small learning rate (0.1) and gradually increase it to see how it affects convergence</li>
            <li>Try different starting points to see if the algorithm converges to different minima</li>
            <li>Use the "Step" button to observe each iteration carefully</li>
            <li>For multivariate functions, observe how the algorithm navigates the contour plot</li>
            <li>For complex functions, try different coloring methods to better understand the function's behavior</li>
        </ul>
    </div>
    
    <div class="section">
        <h2>Troubleshooting</h2>
        <table>
            <tr>
                <th>Issue</th>
                <th>Solution</th>
            </tr>
            <tr>
                <td>Algorithm doesn't converge</td>
                <td>Try reducing the learning rate or choosing a different starting point</td>
            </tr>
            <tr>
                <td>Algorithm oscillates around minimum</td>
                <td>Reduce the learning rate to take smaller steps</td>
            </tr>
            <tr>
                <td>Algorithm moves too slowly</td>
                <td>Increase the learning rate to take larger steps</td>
            </tr>
            <tr>
                <td>Visualization is slow or laggy</td>
                <td>Try using a more powerful device or a different browser</td>
            </tr>
        </table>
    </div>
    
    <div class="note">
        <p><strong>Note:</strong> This visualizer is designed for educational purposes to help understand the 
        gradient descent algorithm. The implementations prioritize clarity and visualization over computational 
        efficiency.</p>
    </div>
</body>
</html>
